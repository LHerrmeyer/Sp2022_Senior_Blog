[
  {
    "path": "posts/2022-07-10-initial-patterns-in-river-flow-data/",
    "title": "Initial patterns in river flow data",
    "description": "Initial patterns in river flow data and their relationship to climatic data.",
    "author": [
      {
        "name": "Logan Herrmeyer",
        "url": {}
      }
    ],
    "date": "2022-07-10",
    "categories": [],
    "contents": "\r\nThe data\r\nI have downloaded data for ten American rivers in different regions\r\nthroughout the US, from the Midwest, the Northeast, the South, and the\r\nWest. These rivers range in size from the wide Mississippi in Baton\r\nRouge, LA, just around 200 miles from it’s delta where it empties into\r\nthe ocean, to the unassuming Peace in Arcadia, FL, lying just a few feet\r\nabove sea level, to the Snake as it flows through the high Snake River\r\nPlain through Idaho Falls, ID.\r\nI downloaded data for these rivers from the US Geological Survey\r\n(USGS). The USGS has many stations for monitoring the flow of hundreds\r\nof different rivers throughout the country, and the data for these\r\nrivers has been recorded for many years, offering a rich data set to\r\npull from.\r\nThe USGS has records going back the furthest for river flow, with\r\nriver water level, or gauge height, data either being only recent, or\r\nnot existing at all. This presents a problem as the height of the river\r\nis necessary to determine if the river has flooded, as rivers generally\r\nhave a certain flood stage height. The USGS helps us with this, as they\r\nprovide what is known as a rating table, which gives an empirical\r\nrelationship between the measured flow of the river, and the height of\r\nthe river. I downloaded this data for each river also, and fit a cubic\r\ncurve to the data in order to calculate the height from the river flow.\r\nThe rating curves are smooth, simple, and monotonic, without significant\r\nirregularities, so a cubic curve does fit well to them.\r\nOne more source of data I pulled in was the Oceanic Niño Index, which\r\nis an index measuring sea surface temperature in the western tropical\r\nPacific. These sea surface temperature anomalies can have significant\r\neffects on weather in many parts of North America, as well as throughout\r\nthe world, especially in the winter season. The El Niño - Southern\r\nOscillation (ENSO) weather pattern has been used to predict river flow\r\nin the past, for example, in the Yangtze River in China.\r\nAnother data source I am pulling in is the monthly ERA5 dataset, from\r\nthe European Centre for Medium-Range Weather Forecasts (ECMWF), which\r\nhas historical weather data, going back to the 1970s, for many different\r\nvariables, such as temperature, precipitation, and snow depth.\r\nParticularly, I am interested in snow depth, as it can help predict\r\nspring flooding in snowy regions, as a high winter snowfall can cause\r\nflooding when the snow melts.\r\nAnnual probability of\r\nflooding\r\nOne thing I discovered when looking at the different rivers, is that\r\nthey have wildly different probabilities of flooding. Here is a\r\nchart:\r\n\r\nCorrelation with ENSO\r\nDifferent rivers in different regions are influenced in varying ways\r\nby the ENSO climate pattern. For example, in Florida, El Niño (above\r\naverage sea surface temperatures in the tropical Pacific) events\r\ngenerally cause above average precipitation in the winter dry season, as\r\ncan be seen in the river stage of the Peace River in Arcadia, FL:\r\nPeace River and ENSOA similar, but weaker pattern can be seen in Louisiana with the\r\nMississippi River. This pattern may be weaker because the Mississippi\r\nRiver is fed by rivers in many different regions of the US, in which\r\nENSO has different impacts on the weather.\r\nMississippi River and ENSOMissing data\r\nSome rivers, such as the Red River in North Dakota, often has missing\r\ndata during the winter, as ice obstructs the ability to measure the\r\nriver flow accurately. Because of this missing data, I will not be\r\npredicting the stage on these seasonally ice covered rivers, and I will\r\nbe predicting future river stage on rivers in warmer regions, that way\r\nthe stage can be predicted year round, and not just outside of the\r\nwinter. I have chosen to predict the Mississippi (Louisiana) and Peace\r\n(Florida) rivers as they have data available year round, and the river\r\nstage has generally good correlation with the ENSO climate pattern.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-07-10T17:44:06-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-07-10-modeling-techniques-for-forecasting-river-flow/",
    "title": "Modeling techniques for forecasting river stage",
    "description": "Methods of modeling time series data for river stage and representing uncertainty.",
    "author": [
      {
        "name": "Logan Herrmeyer",
        "url": {}
      }
    ],
    "date": "2022-07-10",
    "categories": [],
    "contents": "\r\nTime series forecasting is well know to be a difficult problem, and\r\nthere are a few ways to go about it.\r\nThe first way is by making the time series data stationary. This\r\nmeans removing trends from the data, for example seasonal trends. One\r\nway to do this is to subtract the time series value from the median\r\nvalue it has on that day of the year. Another method is differencing,\r\nwhich means transforming the time series data into a difference from the\r\nlast timestep.\r\nOne more method of time series forecasting is binning. Binning time\r\nseries into groups, say by months, make turn the problem into more of a\r\nclassic machine learning problem, as only a smaller number of these\r\nlarger, binned timesteps need to be predicted. In my first models, I\r\ngrouped data by month, and created lag and lead columns, and predicted a\r\ntarget column of whether the river would be flooded or not, with some\r\nsuccess. However, this approach had disadvantages, as the very coarse\r\ngrained data (on timescales of months) can miss out on trends that are\r\npresent in more fine grained data (on the weekly to daily level). As\r\nsuch, I looked for a better alternative, one that predict each day, to\r\nproduce fine grained forecasts usable in a dashboard.\r\nThe method that I ended up using for time series forecasting is a\r\nRecurrent Neural Network (RNN) using Long Short-Term Memory (LSTM)\r\nunits. RNNs are recurrent, meaning they loop back on themselves. Outputs\r\nfrom units in the network are fed back into the network. LSTMs, a type\r\nof neuron used in RNNs, can store information from the past, and it can\r\nbe recalled again in the future. The LSTM has an input, output, and a\r\nforget gate, which allows information to be updated, read, and deleted,\r\nrespectively, which allows the neural network to control the\r\nmemorization process, and allows the network to learn to keep and use\r\nimportant information, while discarding unimportant information. These\r\nRNNs can take in a number of time series steps, and output another\r\nnumber of time series steps to forecast them. In the case of this\r\nproject, the model takes 24 weeks (168 days) of river stage and ENSO\r\ndata (interpolated to daily level from monthly level) and outputs 12\r\nweeks (84 days) of predicted river stage data. The model was made using\r\nTensorFlow using the code below:\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\r\n\r\nmodel = Sequential()\r\nmodel.add(LSTM(\r\n    200,\r\n    batch_input_shape=(batch_size,\r\n    X_train.shape[1], X_train.shape[2]),\r\n    return_sequences=False, stateful=True\r\n))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Dense(1024, activation='relu'))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(Dense(1024, activation='relu'))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(Dense(128))\r\nmodel.add(Dense(y_train.shape[1]))\r\nI fit an LSTM model to both the Peace and Arcadia rivers, and on\r\nholdout validation data, they got \\(R^2\\) scores of 0.64 and 0.39 respectively.\r\nBecause these models do not fit the data with complete accuracy, there\r\nis uncertainty in the models, and we need a way to represent that\r\nuncertainty. For this, I used prediction intervals. These are intervals,\r\nwhich are centered on the predicted value \\(\\hat{y}\\), saying that some \\(p\\)% of the time the true value \\(y\\) will be in the interval. Here is a plot\r\nof a prediction interval on the dashboard:\r\nPrediction interval exampleTo find how wide the prediction interval should be at a certain\r\nprobability level, I had to find the probability distribution of the\r\nerrors, or residuals, of the model. In this case, from plotting and\r\nmetrics of skewness and kurtosis, the residuals of the model were close\r\nto a normal distribution, meaning I could model a prediction interval\r\nbased on a normal distribution. The residuals in the model are normally\r\ndistribted with a mean of 0 (meaning the model is unbiased), and a\r\nstandard deviation of the standard error, also known as the RMSE (root\r\nmean squared error). Since I knew the RMSE, I could construct a. A 95%\r\nprediction interval is simple to construct, because in a normal\r\ndistribution, 95% of the data is within two standard deviations (which\r\nis the RMSE) of the mean (which is 0). However, the RMSE is not a\r\nconstant. Because this is time series data, the inaccuracy of the model\r\nincreases as time increases, as it is harder to predict events further\r\nin the future. I empirically determined how the RMSE increased for each\r\nriver over time using a linear regression (each timestep is one\r\nday):\r\nRMSE and timeNow having an equation that can calculate the standard error/RMSE\r\nfrom the day of prediction, I could now construct a prediction interval.\r\nThe distribution of the residuals can also be used backwards,\r\nspecifically it can be used to calculate the probability of the true\r\nvalue, \\(y\\) being above or below a\r\ncertain value based on \\(\\hat{y}\\). In\r\nthe dashboard, SciPy’s normal cumulative density function (CDF)\r\ncalculates the probability of the true river stage in the future being\r\nabove the flood stage for each predicted day. Then, the dashboard shows\r\nthe maximum probability of a day flooding, along with which day has that\r\nmaximum probability. With the prediction interval and probability\r\ncalculations, a full picture of the predictions in context is given,\r\nallowing people to make more informed decisions based on the data.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-07-16T18:26:27-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-07-10-test-post/",
    "title": "Test post",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Logan Herrmeyer",
        "url": "https://github.com/LHerrmeyer"
      }
    ],
    "date": "2022-07-10",
    "categories": [],
    "contents": "\r\nDistill is a publication format for scientific and technical writing,\r\nnative to the web.\r\nLearn more about using Distill at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-07-10T16:50:48-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-09-welcome-to-my-project/",
    "title": "Welcome to my project",
    "description": "An introduction to my senior project.",
    "author": [
      {
        "name": "Logan Herrmeyer",
        "url": {}
      }
    ],
    "date": "2022-05-09",
    "categories": [],
    "contents": "\r\nFlooding is one of the most costly and common types of natural disaster throughout the world. In the United States, over 90 percent of natural disasters involve flooding, and inflict more damage to both life and property than any other natural hazard.(1)\r\nFlooding in 1997Because of this large hazard, it is is important to prepare for these flooding events ahead of time, to, for example, build structures such as levees and sandbag walls to reduce flooding risk, and to evacuate people and belongings from the potentially flooded area. While modern Numerical Weather Prediction models can predict weather accurately up about ten days in advance (2), these weather models cannot predict the risk of flooding for weeks or months in advance. Ten days may not be enough to adequately prepare for major flooding, but multiple weeks, or even months, gives people more time to sufficiently prepare, and potentially safe lives and property.\r\nMany different climate variables can influence weather in an area weeks or months in advance. For example, El Niño–Southern Oscillation (ENSO), a variation in sea surface temperatures in the tropical Western Pacific Ocean, can have significant impacts on the weather in the US. Generally, during warm, or El Niño events, the northern US has warmer and drier than usual weather, while the southern US has colder and wetter than usual weather. In cold, or, La Niña, events, the opposite generally happens. In cold or mountainous areas, snowpack is another important climate variable that impacts flooding, as snowpack builds for months, and melts later. We can feed this data into a machine learning model to predict how these events impact the probability and expected magnitude of flooding.\r\nFeeding ENSO data into a machine learning model to predict flooding has been used with some success. The monthly flow of the Yangtze, China’s longest river, was predicted in two major flood years and one minor flood year with good accuracy (\\(R^2\\)=0.8) using historical streamflow data, and ENSO data.(3) Particularly, the ENSO data helped determine the timing and magnitude of the flooding event.\r\nThrough climatic variables and historical data, I will predict streamflows of rivers months in advance, and calculate the probability of exceeding flood stage, as well as the predicted maximum streamflow.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-05-14T22:42:15-06:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to Spring 2022 Senior Project",
    "description": "Welcome to our new blog, Spring 2022 Senior Project. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Nora Jones",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2022-05-09",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-07-10T17:25:52-06:00",
    "input_file": {}
  }
]
